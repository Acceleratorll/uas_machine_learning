{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anggota Kelompok 4\n",
    "<br><br>\n",
    "No&nbsp;Nama &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;NIM\n",
    "<br>\n",
    "1   &ensp;Achmad Wibawa           &emsp;&emsp;&emsp;&emsp;2041720174<br>\n",
    "3   &ensp;Ahmad Abid              &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;2041720179<br>\n",
    "4   &ensp;Ahmad Thariq Ramadhan   2041720200<br>\n",
    "10  &nbsp;Dewangga Putra          &emsp;&emsp;&emsp;&emsp;2042720222<br>\n",
    "17  &nbsp;Maulana Rosandy         &emsp;&emsp;&emsp;2041720120<br>\n",
    "18  &nbsp;Moch Fajrul Falah       &emsp;&emsp;&emsp;2041720070<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1607163989674590209</td>\n",
       "      <td>1607163989674590209</td>\n",
       "      <td>2022-12-26 06:58:49 SE Asia Standard Time</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>06:58:49</td>\n",
       "      <td>700</td>\n",
       "      <td>1046084008742801408</td>\n",
       "      <td>collegemenfess</td>\n",
       "      <td>COLLE | CEK PINNEDðŸ˜Ž</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1607163313649246208</td>\n",
       "      <td>1607163313649246208</td>\n",
       "      <td>2022-12-26 06:56:08 SE Asia Standard Time</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>06:56:08</td>\n",
       "      <td>700</td>\n",
       "      <td>1046084008742801408</td>\n",
       "      <td>collegemenfess</td>\n",
       "      <td>COLLE | CEK PINNEDðŸ˜Ž</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1607162707584876544</td>\n",
       "      <td>1607162707584876544</td>\n",
       "      <td>2022-12-26 06:53:43 SE Asia Standard Time</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>06:53:43</td>\n",
       "      <td>700</td>\n",
       "      <td>1046084008742801408</td>\n",
       "      <td>collegemenfess</td>\n",
       "      <td>COLLE | CEK PINNEDðŸ˜Ž</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1607162057639755777</td>\n",
       "      <td>1607162057639755777</td>\n",
       "      <td>2022-12-26 06:51:08 SE Asia Standard Time</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>06:51:08</td>\n",
       "      <td>700</td>\n",
       "      <td>1046084008742801408</td>\n",
       "      <td>collegemenfess</td>\n",
       "      <td>COLLE | CEK PINNEDðŸ˜Ž</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1607161879671222272</td>\n",
       "      <td>1607161879671222272</td>\n",
       "      <td>2022-12-26 06:50:26 SE Asia Standard Time</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>06:50:26</td>\n",
       "      <td>700</td>\n",
       "      <td>1046084008742801408</td>\n",
       "      <td>collegemenfess</td>\n",
       "      <td>COLLE | CEK PINNEDðŸ˜Ž</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id  \\\n",
       "0  1607163989674590209  1607163989674590209   \n",
       "1  1607163313649246208  1607163313649246208   \n",
       "2  1607162707584876544  1607162707584876544   \n",
       "3  1607162057639755777  1607162057639755777   \n",
       "4  1607161879671222272  1607161879671222272   \n",
       "\n",
       "                                  created_at        date      time  timezone  \\\n",
       "0  2022-12-26 06:58:49 SE Asia Standard Time  2022-12-26  06:58:49       700   \n",
       "1  2022-12-26 06:56:08 SE Asia Standard Time  2022-12-26  06:56:08       700   \n",
       "2  2022-12-26 06:53:43 SE Asia Standard Time  2022-12-26  06:53:43       700   \n",
       "3  2022-12-26 06:51:08 SE Asia Standard Time  2022-12-26  06:51:08       700   \n",
       "4  2022-12-26 06:50:26 SE Asia Standard Time  2022-12-26  06:50:26       700   \n",
       "\n",
       "               user_id        username                 name  place  ... geo  \\\n",
       "0  1046084008742801408  collegemenfess  COLLE | CEK PINNEDðŸ˜Ž    NaN  ... NaN   \n",
       "1  1046084008742801408  collegemenfess  COLLE | CEK PINNEDðŸ˜Ž    NaN  ... NaN   \n",
       "2  1046084008742801408  collegemenfess  COLLE | CEK PINNEDðŸ˜Ž    NaN  ... NaN   \n",
       "3  1046084008742801408  collegemenfess  COLLE | CEK PINNEDðŸ˜Ž    NaN  ... NaN   \n",
       "4  1046084008742801408  collegemenfess  COLLE | CEK PINNEDðŸ˜Ž    NaN  ... NaN   \n",
       "\n",
       "  source user_rt_id user_rt retweet_id  reply_to  retweet_date  translate  \\\n",
       "0    NaN        NaN     NaN        NaN        []           NaN        NaN   \n",
       "1    NaN        NaN     NaN        NaN        []           NaN        NaN   \n",
       "2    NaN        NaN     NaN        NaN        []           NaN        NaN   \n",
       "3    NaN        NaN     NaN        NaN        []           NaN        NaN   \n",
       "4    NaN        NaN     NaN        NaN        []           NaN        NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('colle_scrap.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(data.duplicated(subset=['tweet']).sum())\n",
    "data.drop_duplicates(subset=['tweet'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(data['tweet']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     dimana tempat kalian berkeluh kesah soal kehi...\n",
       "1     temen2 pernah gini gak  tiba tiba muncul some...\n",
       "2     guys  ada yang mau bantu like tugasku gak di ...\n",
       "3            kampus swasta tuh lg libir nataru ga sih \n",
       "4     cara chat dosbim buat follow up masalah bab1 ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "data1 = data.copy()\n",
    "\n",
    "rm_rt_url = lambda x: re.sub('(\\[cm\\]|\\[CM\\]|\\[Cm\\]|\\[cM\\]) | (@[A-Za-z0â€“9\\w]+) | (@\\w+:) | (\\w+:\\/\\/\\S+) | (www.\\S+)',' ',x)\n",
    "rm_punct = lambda x: re.sub('\\W', ' ', x)\n",
    "\n",
    "data1['tweet'] = data.tweet.map(rm_rt_url).map(rm_punct)\n",
    "data1['tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     dimana tempat kalian berkeluh kesah soal kehi...\n",
       "1     temen2 pernah gini gak  tiba tiba muncul some...\n",
       "2     guys  ada yang mau bantu like tugasku gak di ...\n",
       "3            kampus swasta tuh lg libir nataru ga sih \n",
       "4     cara chat dosbim buat follow up masalah bab1 ...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['tweet'].str.lower()\n",
    "data1['tweet'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing menggunakan NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [dimana, tempat, kalian, berkeluh, kesah, soal...\n",
       "1    [temen, 2, pernah, gini, gak, tiba, tiba, munc...\n",
       "2    [guys, ada, yang, mau, bantu, like, tugasku, g...\n",
       "3    [kampus, swasta, tuh, lg, libir, nataru, ga, sih]\n",
       "4    [cara, chat, dosbim, buat, follow, up, masalah...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "token = TweetTokenizer()\n",
    "\n",
    "tweet = data1['tweet'].apply(token.tokenize)\n",
    "tweet.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming dengan SnowballStemmer dan Sastrawi\n",
    "\n",
    "Snowballstemmer lebih cepat 10x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [mana, tempat, kali, keluh, kesah, soal, hidup...\n",
       "1    [temen, 2, pernah, gini, gak, tiba, tiba, munc...\n",
       "2    [guys, ada, yang, mau, bantu, like, tugas, gak...\n",
       "3    [kampus, swasta, tuh, lg, libir, nataru, ga, sih]\n",
       "4    [cara, chat, dosbim, buat, follow, up, masa, b...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snowballstemmer import stemmer\n",
    "snow_stem = stemmer('indonesian')\n",
    "\n",
    "\n",
    "def snow_stemming(text):\n",
    "    stem_text = [snow_stem.stemWord(word) for word in text]\n",
    "    return stem_text\n",
    "\n",
    "tweet = tweet.apply(lambda x: snow_stemming(x))\n",
    "\n",
    "tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dimana tempat kalian berkeluh kesah soal kehi...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>temen2 pernah gini gak  tiba tiba muncul some...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guys  ada yang mau bantu like tugasku gak di ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kampus swasta tuh lg libir nataru ga sih</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cara chat dosbim buat follow up masalah bab1 ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  polarity  \\\n",
       "0   dimana tempat kalian berkeluh kesah soal kehi...   Neutral       0.0   \n",
       "1   temen2 pernah gini gak  tiba tiba muncul some...  Negative      -0.5   \n",
       "2   guys  ada yang mau bantu like tugasku gak di ...   Neutral       0.0   \n",
       "3          kampus swasta tuh lg libir nataru ga sih    Neutral       0.0   \n",
       "4   cara chat dosbim buat follow up masalah bab1 ...   Neutral       0.0   \n",
       "\n",
       "   subjectivity  \n",
       "0           0.0  \n",
       "1           0.9  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "for row in data1.itertuples():\n",
    "    tweet = data1.at[row[0], 'tweet']\n",
    "#run sentiment using TextBlob\n",
    "    analysis = TextBlob(tweet)\n",
    "    data1.at[row[0], 'polarity'] = analysis.sentiment[0]\n",
    "    data1.at[row[0], 'subjectivity'] = analysis.sentiment[1]\n",
    "#Create Positive / negative column depending on polarity\n",
    "    if analysis.sentiment[0]>0:\n",
    "        data1.at[row[0], 'sentiment'] = \"Positive\"\n",
    "    elif analysis.sentiment[0]<0:\n",
    "        data1.at[row[0], 'sentiment'] = \"Negative\"\n",
    "    else:\n",
    "        data1.at[row[0], 'sentiment'] = \"Neutral\"\n",
    "    \n",
    "\n",
    "data1[['tweet','sentiment','polarity','subjectivity']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     4591\n",
       "Positive     268\n",
       "Negative     117\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = data1['sentiment'].value_counts()\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4976,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = data1['tweet'].values\n",
    "y = data1['sentiment'].values\n",
    "\n",
    "# Encode Label\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform(y)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train Test\n",
    "# Split dulu untuk menghindari leaking information\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Akurasi fitur TF-IDF (training): 0.921105527638191\n",
      "Akurasi fitur TF-IDF (testing): 0.929718875502008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "## 1st Experiment\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "mnb_tf = MultinomialNB()\n",
    "\n",
    "mnb_tf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict train\n",
    "y_tf_train = mnb_tf.predict(X_train_tfidf)\n",
    "acc_tf_train = accuracy_score(y_train, y_tf_train)\n",
    "\n",
    "# Predict test\n",
    "y_tf_test = mnb_tf.predict(X_test_tfidf)\n",
    "acc_tf_test = accuracy_score(y_test, y_tf_test)\n",
    "\n",
    "# Print Hasil\n",
    "print('==========')\n",
    "print(f'Akurasi fitur TF-IDF (training): {acc_tf_train}')\n",
    "print(f'Akurasi fitur TF-IDF (testing): {acc_tf_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Akurasi fitur TF-IDF (training): 0.9608040201005025\n",
      "Akurasi fitur TF-IDF (testing): 0.9337349397590361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "\n",
    "svc_tf = SVC()\n",
    "\n",
    "svc_tf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict train\n",
    "y_tf_train = svc_tf.predict(X_train_tfidf)\n",
    "acc_tf_train = accuracy_score(y_train, y_tf_train)\n",
    "\n",
    "# Predict test\n",
    "y_tf_test = svc_tf.predict(X_test_tfidf)\n",
    "acc_tf_test = accuracy_score(y_test, y_tf_test)\n",
    "\n",
    "# Print Hasil\n",
    "print('==========')\n",
    "print(f'Akurasi fitur TF-IDF (training): {acc_tf_train}')\n",
    "print(f'Akurasi fitur TF-IDF (testing): {acc_tf_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a file\n",
    "with open(\"mnb.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mnb_tf, f)\n",
    "    \n",
    "with open(\"svc.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svc_tf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2bd553e7001daf5eeb69e1661d0b9033f7a52c956da7d0f70fc9bc4480b30bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
